A density matrix is a matrix that describes a quantum system in a mixed state, a statistical ensemble of several quantum states. This should be contrasted with a single state vector that describes a quantum system in a pure state. The density matrix is the quantum-mechanical analogue to a phase-space probability measure (probability distribution of position and momentum) in classical statistical mechanics.
Mixed states arise in situations where the experimenter does not know which particular states are being manipulated. Examples include a system in thermal equilibrium (or additionally chemical equilibrium) or a system with an uncertain or randomly varying preparation history (so one does not know which pure state the system is in). Also, if a quantum system has two or more subsystems that are entangled, then each subsystem must be treated as a mixed state even if the complete system is in a pure state. The density matrix is also a crucial tool in quantum decoherence theory.
The density matrix is a representation of a linear operator called the density operator. The close relationship between matrices and operators is a basic concept in linear algebra. In practice, the terms density matrix and density operator are often used interchangeably. Both matrix and operator are self-adjoint (or Hermitian), positive semi-definite, of trace one, and may be infinite-dimensional.
The formalism of density operators and matrices was introduced by John von Neumann in 1927 and independently, but less systematically by Lev Landau and Felix Bloch in 1927 and 1946 respectively.
Suppose a quantum system may be found in state
          |
          ψ
            1
        ⟩
    {\displaystyle |\psi _{1}\rangle }
with probability p1, or it may be found in state
          |
          ψ
            2
        ⟩
    {\displaystyle |\psi _{2}\rangle }
with probability p2, and so on. The density operator for this system is
              ρ
              ^
        =
          ∑
            i
          p
            i
          |
          ψ
            i
        ⟩
        ⟨
          ψ
            i
          |
        ,
    {\displaystyle {\hat {\rho }}=\sum _{i}p_{i}|\psi _{i}\rangle \langle \psi _{i}|,}
where
        {
          |
          ψ
            i
        ⟩
        }
    {\displaystyle \{|\psi _{i}\rangle \}}
is a spanning set of normalized Hilbert space vectors, but not necessarily orthogonal. The numbers pi satisfy, since they are probabilities,
        0
        ≤
          p
            i
        ≤
        1
        ,
          ∑
            i
          p
            i
        =
        1
    {\displaystyle 0\leq p_{i}\leq 1,\quad \sum _{i}p_{i}=1}
  .
By choosing an orthonormal basis
        {
          |
          u
            m
        ⟩
        }
        ,
    {\displaystyle \{|u_{m}\rangle \},}
one may resolve the density operator into the density matrix, whose elements are
          ρ
            m
            n
        =
          ∑
            i
          p
            i
        ⟨
          u
            m
          |
          ψ
            i
        ⟩
        ⟨
          ψ
            i
          |
          u
            n
        ⟩
        =
        ⟨
          u
            m
          |
              ρ
              ^
          |
          u
            n
        ⟩
        .
    {\displaystyle \rho _{mn}=\sum _{i}p_{i}\langle u_{m}|\psi _{i}\rangle \langle \psi _{i}|u_{n}\rangle =\langle u_{m}|{\hat {\rho }}|u_{n}\rangle .}
The density operator can also be defined in terms of the density matrix,
              ρ
              ^
        =
          ∑
            m
            n
          |
          u
            m
        ⟩
          ρ
            m
            n
        ⟨
          u
            n
          |
        .
    {\displaystyle {\hat {\rho }}=\sum _{mn}|u_{m}\rangle \rho _{mn}\langle u_{n}|.}
For an operator
              A
              ^
    {\displaystyle {\hat {A}}}
(which may describe an observable A of the system), the ensemble average
        ⟨
        A
        ⟩
    {\displaystyle \langle A\rangle }
is given by
        ⟨
        A
        ⟩
        =
          ∑
            i
          p
            i
        ⟨
          ψ
            i
          |
              A
              ^
          |
          ψ
            i
        ⟩
        =
          ∑
            m
            n
        ⟨
          u
            m
          |
              ρ
              ^
          |
          u
            n
        ⟩
        ⟨
          u
            n
          |
              A
              ^
          |
          u
            m
        ⟩
        =
          ∑
            m
            n
          ρ
            m
            n
          A
            n
            m
        =
        tr
        ⁡
        (
        ρ
        A
        )
        .
    {\displaystyle \langle A\rangle =\sum _{i}p_{i}\langle \psi _{i}|{\hat {A}}|\psi _{i}\rangle =\sum _{mn}\langle u_{m}|{\hat {\rho }}|u_{n}\rangle \langle u_{n}|{\hat {A}}|u_{m}\rangle =\sum _{mn}\rho _{mn}A_{nm}=\operatorname {tr} (\rho A).}
Here the quantity
        ⟨
          ψ
            i
          |
              A
              ^
          |
          ψ
            i
        ⟩
    {\displaystyle \langle \psi _{i}|{\hat {A}}|\psi _{i}\rangle }
is just the ordinary expectation value of the operator in the pure state ψi. In words, the expectation value of A for the mixed state is the sum of the expectation values of A for each of the pure states
          |
          ψ
            i
        ⟩
    {\displaystyle |\psi _{i}\rangle }
weighted by the probabilities pi and can be computed as the trace of the product of the density matrix with the matrix representation of A in the same basis. This is basis independent since traces are invariant under unitary transformations.
In quantum mechanics, a quantum system is represented by a state vector (or ket) 
          |
        ψ
        ⟩
    {\displaystyle |\psi \rangle }
  . A quantum system with a state vector 
          |
        ψ
        ⟩
    {\displaystyle |\psi \rangle }
   is called a pure state. However, it is also possible for a system to be in a statistical ensemble of different state vectors: For example, there may be a 50% probability that the state vector is 
          |
          ψ
            1
        ⟩
    {\displaystyle |\psi _{1}\rangle }
   and a 50% chance that the state vector is 
          |
          ψ
            2
        ⟩
    {\displaystyle |\psi _{2}\rangle }
  . This system would be in a mixed state. The density matrix is especially useful for mixed states, because any state, pure or mixed, can be characterized by a single density matrix.
A mixed state is different from a quantum superposition. In fact, a quantum superposition of pure states is another pure state, for example 
          |
        ψ
        ⟩
        =
        (
          |
          ψ
            1
        ⟩
        +
          |
          ψ
            2
        ⟩
        )
          /
            2
    {\displaystyle |\psi \rangle =(|\psi _{1}\rangle +|\psi _{2}\rangle )/{\sqrt {2}}}
  .
A state is pure if and only if its density matrix 
        ρ
    {\displaystyle \rho }
   satisfies 
          t
          r
        (
          ρ
            2
        )
        =
        1
    {\displaystyle \mathrm {tr} (\rho ^{2})=1}
  .
An example of pure and mixed states is light polarization. Photons can have two helicities, corresponding to two orthogonal quantum states, 
          |
        R
        ⟩
    {\displaystyle |R\rangle }
   (right circular polarization) and 
          |
        L
        ⟩
    {\displaystyle |L\rangle }
   (left circular polarization). A photon can also be in a superposition state, such as 
        (
          |
        R
        ⟩
        +
          |
        L
        ⟩
        )
          /
            2
    {\displaystyle (|R\rangle +|L\rangle )/{\sqrt {2}}}
   (vertical polarization) or 
        (
          |
        R
        ⟩
        −
          |
        L
        ⟩
        )
          /
            2
    {\displaystyle (|R\rangle -|L\rangle )/{\sqrt {2}}}
   (horizontal polarization). More generally, it can be in any state 
        α
          |
        R
        ⟩
        +
        β
          |
        L
        ⟩
    {\displaystyle \alpha |R\rangle +\beta |L\rangle }
  , corresponding to linear, circular, or elliptical polarization. If we pass 
        (
          |
        R
        ⟩
        +
          |
        L
        ⟩
        )
          /
            2
    {\displaystyle (|R\rangle +|L\rangle )/{\sqrt {2}}}
   polarized light through a circular polarizer which allows either only 
          |
        R
        ⟩
    {\displaystyle |R\rangle }
   polarized light, or only 
          |
        L
        ⟩
    {\displaystyle |L\rangle }
   polarized light, intensity would be reduced by half in both cases. This may make it seem like half of the photons are in state 
          |
        R
        ⟩
    {\displaystyle |R\rangle }
   and the other half in state 
          |
        L
        ⟩
    {\displaystyle |L\rangle }
  . But this is not correct: Both 
          |
        R
        ⟩
    {\displaystyle |R\rangle }
   and 
          |
        L
        ⟩
    {\displaystyle |L\rangle }
   photons are partly absorbed by a vertical linear polarizer, but the 
        (
          |
        R
        ⟩
        +
          |
        L
        ⟩
        )
          /
            2
    {\displaystyle (|R\rangle +|L\rangle )/{\sqrt {2}}}
   light will pass through that polarizer with no absorption whatsoever.
However, unpolarized light (such as the light from an incandescent light bulb) is different from any state like 
        α
          |
        R
        ⟩
        +
        β
          |
        L
        ⟩
    {\displaystyle \alpha |R\rangle +\beta |L\rangle }
   (linear, circular, or elliptical polarization). Unlike linearly or elliptically polarized light, it passes through a polarizer with 50% intensity loss whatever the orientation of the polarizer; and unlike circularly polarized light, it cannot be made linearly polarized with any wave plate because randomly oriented polarization will emerge from a wave plate with random orientation. Indeed, unpolarized light cannot be described as any state of the form 
        α
          |
        R
        ⟩
        +
        β
          |
        L
        ⟩
    {\displaystyle \alpha |R\rangle +\beta |L\rangle }
   in a definite sense. However, unpolarized light can be described with ensemble averages, e.g. that each photon is either 
          |
        R
        ⟩
    {\displaystyle |R\rangle }
   with 50% probability or 
          |
        L
        ⟩
    {\displaystyle |L\rangle }
   with 50% probability. The same behavior would occur if each photon was either vertically polarized with 50% probability or horizontally polarized with 50% probability.
Therefore, unpolarized light cannot be described by any pure state, but can be described as a statistical ensemble of pure states in at least two ways (the ensemble of half left and half right circularly polarized, or the ensemble of half vertically and half horizontally linearly polarized). These two ensembles are completely indistinguishable experimentally, and therefore they are considered the same mixed state. One of the advantages of the density matrix is that there is just one density matrix for each mixed state, whereas there are many statistical ensembles of pure states for each mixed state. Nevertheless, the density matrix contains all the information necessary to calculate any measurable property of the mixed state.
Where do mixed states come from? To answer that, consider how to generate unpolarized light. One way is to use a system in thermal equilibrium, a statistical mixture of enormous numbers of microstates, each with a certain probability (the Boltzmann factor), switching rapidly from one to the next due to thermal fluctuations. Thermal randomness explains why an incandescent light bulb, for example, emits unpolarized light. A second way to generate unpolarized light is to introduce uncertainty in the preparation of the system, for example, passing it through a birefringent crystal with a rough surface, so that slightly different parts of the beam acquire different polarizations. A third way to generate unpolarized light uses an EPR setup: A radioactive decay can emit two photons traveling in opposite directions, in the quantum state 
        (
          |
        R
        ,
        L
        ⟩
        +
          |
        L
        ,
        R
        ⟩
        )
          /
            2
    {\displaystyle (|R,L\rangle +|L,R\rangle )/{\sqrt {2}}}
  . The two photons together are in a pure state, but if you only look at one of the photons and ignore the other, the photon behaves just like unpolarized light.
More generally, mixed states commonly arise from a statistical mixture of the starting state (such as in thermal equilibrium), from uncertainty in the preparation procedure (such as slightly different paths that a photon can travel), or from looking at a subsystem entangled with something else.
The state vector 
          |
        ψ
        ⟩
    {\displaystyle |\psi \rangle }
   of a pure state completely determines the statistical behavior of a measurement. For concreteness, take an observable quantity, and let A be the associated observable operator that has a representation on the Hilbert space 
            H
    {\displaystyle {\mathcal {H}}}
   of the quantum system. For any real-valued, analytical function F defined on the real numbers, suppose that F(A) is the result of applying F to the outcome of a measurement. The expectation value of F(A) is
        ⟨
        ψ
          |
        F
        (
        A
        )
          |
        ψ
        ⟩
        .
    {\displaystyle \langle \psi |F(A)|\psi \rangle \,.}
Now consider a mixed state prepared by statistically combining two different pure states 
          |
        ψ
        ⟩
    {\displaystyle |\psi \rangle }
   and 
          |
        ϕ
        ⟩
    {\displaystyle |\phi \rangle }
  , with the associated probabilities p and 1 − p, respectively. The associated probabilities mean that the preparation process for the quantum system ends in the state 
          |
        ψ
        ⟩
    {\displaystyle |\psi \rangle }
   with probability p and in the state 
          |
        ϕ
        ⟩
    {\displaystyle |\phi \rangle }
   with probability 1 − p.
It is not hard to show that the statistical properties of the observable for the system prepared in such a mixed state are completely determined. However, there is no state vector 
          |
        ξ
        ⟩
    {\displaystyle |\xi \rangle }
   which determines this statistical behavior in the sense that the expectation value of F(A) is
        ⟨
        ξ
          |
        F
        (
        A
        )
          |
        ξ
        ⟩
        .
    {\displaystyle \langle \xi |F(A)|\xi \rangle \,.}
Nevertheless, there is a unique operator ρ such that the expectation value of F(A) can be written as
        tr
        ⁡
        [
        ρ
        F
        (
        A
        )
        ]
        ,
    {\displaystyle \operatorname {tr} [\rho F(A)]\,,}
where the operator ρ is the density operator of the mixed system. A simple calculation shows that the operator ρ for the above discussion is given by
        ρ
        =
        p
          |
        ψ
        ⟩
        ⟨
        ψ
          |
        +
        (
        1
        −
        p
        )
          |
        ϕ
        ⟩
        ⟨
        ϕ
          |
        .
    {\displaystyle \rho =p|\psi \rangle \langle \psi |+(1-p)|\phi \rangle \langle \phi |\,.}
For the above example of unpolarized light, the density operator is
        ρ
        =
              1
              2
          |
        R
        ⟩
        ⟨
        R
          |
        +
              1
              2
          |
        L
        ⟩
        ⟨
        L
          |
        .
    {\displaystyle \rho ={\tfrac {1}{2}}|R\rangle \langle R|+{\tfrac {1}{2}}|L\rangle \langle L|.}
For a finite-dimensional function space, the most general density operator is of the form
        ρ
        =
          ∑
            j
          p
            j
          |
          ψ
            j
        ⟩
        ⟨
          ψ
            j
          |
    {\displaystyle \rho =\sum _{j}p_{j}|\psi _{j}\rangle \langle \psi _{j}|}
where the coefficients pj are non-negative and add up to one. This represents a statistical mixture of pure states. If the given system is closed, then one can think of a mixed state as representing a single system with an uncertain preparation history, as explicitly detailed above; or we can regard the mixed state as representing an ensemble of systems, i.e. a large number of copies of the system in question, where pj is the proportion of the ensemble being in the state 
            |
            ψ
              j
          ⟩
    {\displaystyle \textstyle |\psi _{j}\rangle }
  . An ensemble is described by a pure state if every copy of the system in that ensemble is in the same state, i.e. it is a pure ensemble. If the system is not closed, however, then it is simply not correct to claim that it has some definite but unknown state vector, as the density operator may record physical entanglements to other systems.
Consider a quantum ensemble of size N with occupancy numbers n1, n2,...,nk corresponding to the orthonormal states 
            |
          1
          ⟩
          ,
          .
          .
          .
          ,
            |
          k
          ⟩
    {\displaystyle \textstyle |1\rangle ,...,|k\rangle }
  , respectively, where n1+...+nk = N, and, thus, the coefficients pj = nj /N. For a pure ensemble, where all N particles are in state 
            |
          i
          ⟩
    {\displaystyle \textstyle |i\rangle }
  , we have nj = 0, for all j ≠ i, from which we recover the corresponding density operator 
          ρ
          =
            |
          i
          ⟩
          ⟨
          i
            |
    {\displaystyle \textstyle \rho =|i\rangle \langle i|}
  . However, the density operator of a mixed state does not capture all the information about the ingredients that went into the mixture; in particular, the coefficients pj and the kets ψj are not recoverable from the operator ρ without additional information. This non-uniqueness implies that different ensembles or mixtures may correspond to the same density operator. Such equivalent ensembles or mixtures cannot be distinguished by measurement of observables alone. This equivalence can be characterized precisely. Two ensembles ψ, ψ' define the same density operator if and only if there is a matrix U with
          U
            ∗
        U
        =
        I
    {\displaystyle U^{*}U=I}
i.e., U is unitary and such that
          |
          ψ
            i
          ′
        ⟩
              p
                i
              ′
        =
          ∑
            j
          u
            i
            j
          |
          ψ
            j
        ⟩
              p
                j
        .
    {\displaystyle |\psi _{i}'\rangle {\sqrt {p_{i}'}}=\sum _{j}u_{ij}|\psi _{j}\rangle {\sqrt {p_{j}}}.}
This is simply a restatement of the following fact from linear algebra: for two square matrices M and N, M M* = N N* if and only if M = NU for some unitary U. (See square root of a matrix for more details.) Thus there is a unitary freedom in the ket mixture or ensemble that gives the same density operator. However, if the kets making up the mixture are restricted to be orthonormal, then the original probabilities pj are recoverable as the eigenvalues of the density matrix.
In operator language, a density operator is a positive semidefinite, hermitian operator of trace 1 acting on the state space. A density operator describes a pure state if it is a rank one projection. Equivalently, a density operator ρ describes a pure state if and only if
        ρ
        =
          ρ
            2
    {\displaystyle \;\rho =\rho ^{2}}
  ,
i.e. the state is idempotent. This is true regardless of whether H is finite-dimensional or not.
Geometrically, when the state is not expressible as a convex combination of other states, it is a pure state. The family of mixed states is a convex set and a state is pure if it is an extremal point of that set.
It follows from the spectral theorem for compact self-adjoint operators that every mixed state is a countable convex combination of pure states. This representation is not unique. Furthermore, a theorem of Andrew Gleason states that certain functions defined on the family of projections and taking values in [0,1] (which can be regarded as quantum analogues of probability measures) are determined by unique mixed states. See quantum logic for more details.
Let A be an observable of the system, and suppose the ensemble is in a mixed state such that each of the pure states 
            |
            ψ
              j
          ⟩
    {\displaystyle \textstyle |\psi _{j}\rangle }
   occurs with probability pj. Then the corresponding density operator is:
        ρ
        =
          ∑
            j
          p
            j
          |
          ψ
            j
        ⟩
        ⟨
          ψ
            j
          |
        .
    {\displaystyle \rho =\sum _{j}p_{j}|\psi _{j}\rangle \langle \psi _{j}|.}
The expectation value of the measurement can be calculated by extending from the case of pure states (see Measurement in quantum mechanics):
        ⟨
        A
        ⟩
        =
          ∑
            j
          p
            j
        ⟨
          ψ
            j
          |
        A
          |
          ψ
            j
        ⟩
        =
          ∑
            j
          p
            j
        tr
        ⁡
          (
            |
            ψ
              j
          ⟩
          ⟨
            ψ
              j
            |
          A
          )
        =
          ∑
            j
        tr
        ⁡
          (
            p
              j
            |
            ψ
              j
          ⟩
          ⟨
            ψ
              j
            |
          A
          )
        =
        tr
        ⁡
          (
            ∑
              j
            p
              j
            |
            ψ
              j
          ⟩
          ⟨
            ψ
              j
            |
          A
          )
        =
        tr
        ⁡
        (
        ρ
        A
        )
        ,
    {\displaystyle \langle A\rangle =\sum _{j}p_{j}\langle \psi _{j}|A|\psi _{j}\rangle =\sum _{j}p_{j}\operatorname {tr} \left(|\psi _{j}\rangle \langle \psi _{j}|A\right)=\sum _{j}\operatorname {tr} \left(p_{j}|\psi _{j}\rangle \langle \psi _{j}|A\right)=\operatorname {tr} \left(\sum _{j}p_{j}|\psi _{j}\rangle \langle \psi _{j}|A\right)=\operatorname {tr} (\rho A),}
where 
        tr
    {\displaystyle \operatorname {tr} }
   denotes trace. Moreover, if A has spectral resolution
        A
        =
          ∑
            i
          a
            i
          |
          a
            i
        ⟩
        ⟨
          a
            i
          |
        =
          ∑
            i
          a
            i
          P
            i
        ,
    {\displaystyle A=\sum _{i}a_{i}|a_{i}\rangle \langle a_{i}|=\sum _{i}a_{i}P_{i},}
where 
          P
            i
        =
          |
          a
            i
        ⟩
        ⟨
          a
            i
          |
    {\displaystyle P_{i}=|a_{i}\rangle \langle a_{i}|}
  , the corresponding density operator after the measurement is given by:
          ρ
          ′
        =
          ∑
            i
          P
            i
        ρ
          P
            i
        .
    {\displaystyle \;\rho '=\sum _{i}P_{i}\rho P_{i}.}
Note that the above density operator describes the full ensemble after measurement. The sub-ensemble for which the measurement result was the particular value ai is described by the different density operator
          ρ
            i
          ′
        =
                P
                  i
              ρ
                P
                  i
              tr
              ⁡
              [
              ρ
                P
                  i
              ]
        .
    {\displaystyle \rho _{i}'={\frac {P_{i}\rho P_{i}}{\operatorname {tr} [\rho P_{i}]}}.}
This is true assuming that 
            |
            a
              i
          ⟩
    {\displaystyle \textstyle |a_{i}\rangle }
   is the only eigenket (up to phase) with eigenvalue ai; more generally, Pi in this expression would be replaced by the projection operator into the eigenspace corresponding to eigenvalue ai.
The von Neumann entropy 
        S
    {\displaystyle S}
   of a mixture can be expressed in terms of the eigenvalues of 
        ρ
    {\displaystyle \rho }
   or in terms of the trace and logarithm of the density operator 
        ρ
    {\displaystyle \rho }
  . Since 
        ρ
    {\displaystyle \rho }
   is a positive semi-definite operator, it has a spectral decomposition such that 
        ρ
        =
          ∑
            i
          λ
            i
          |
          φ
            i
        ⟩
        ⟨
          φ
            i
          |
    {\displaystyle \rho =\sum _{i}\lambda _{i}|\varphi _{i}\rangle \langle \varphi _{i}|}
   where 
          |
          φ
            i
        ⟩
    {\displaystyle |\varphi _{i}\rangle }
   are orthonormal vectors, 
          λ
            i
        >
        0
    {\displaystyle \lambda _{i}>0}
   and 
        ∑
          λ
            i
        =
        1
    {\displaystyle \sum \lambda _{i}=1}
  . Then the entropy of a quantum system with density matrix 
        ρ
    {\displaystyle \rho }
   is
        S
        =
        −
          ∑
            i
          λ
            i
        ln
          λ
            i
        =
        −
        tr
        ⁡
        (
        ρ
        ln
        ⁡
        ρ
        )
        .
    {\displaystyle S=-\sum _{i}\lambda _{i}\ln \,\lambda _{i}=-\operatorname {tr} (\rho \ln \rho )\quad .}
Also it can be shown that
        S
          (
          ρ
          =
            ∑
              i
            p
              i
            ρ
              i
          )
        =
        H
        (
          p
            i
        )
        +
          ∑
            i
          p
            i
        S
        (
          ρ
            i
        )
    {\displaystyle S\left(\rho =\sum _{i}p_{i}\rho _{i}\right)=H(p_{i})+\sum _{i}p_{i}S(\rho _{i})}
when 
          ρ
            i
    {\displaystyle \rho _{i}}
   have orthogonal support, where 
        H
        (
        p
        )
    {\displaystyle H(p)}
   is the Shannon entropy. This entropy can increase but never decrease with a projective measurement, however generalised measurements can decrease entropy. The entropy of a pure state is zero, while that of a proper mixture always greater than zero. Therefore, a pure state may be converted into a mixture by a measurement, but a proper mixture can never be converted into a pure state. Thus the act of measurement induces a fundamental irreversible change on the density matrix; this is analogous to the "collapse" of the state vector, or wavefunction collapse. Perhaps counterintuitively, the measurement actually decreases information by erasing quantum interference in the composite system—cf. quantum entanglement, einselection, and quantum decoherence.
(A subsystem of a larger system can be turned from a mixed to a pure state, but only by increasing the von Neumann entropy elsewhere in the system. This is analogous to how the entropy of an object can be lowered by putting it in a refrigerator: The air outside the refrigerator's heat-exchanger warms up, gaining even more entropy than was lost by the object in the refrigerator. See second law of thermodynamics. See Entropy in thermodynamics and information theory.)
Just as the Schrödinger equation describes how pure states evolve in time, the von Neumann equation (also known as the Liouville–von Neumann equation) describes how a density operator evolves in time (in fact, the two equations are equivalent, in the sense that either can be derived from the other.) The von Neumann equation dictates that
        i
        ℏ
              ∂
              ρ
              ∂
              t
        =
        [
        H
        ,
        ρ
        ]
        ,
    {\displaystyle i\hbar {\frac {\partial \rho }{\partial t}}=[H,\rho ]~,}
where the brackets denote a commutator.
Note that this equation only holds when the density operator is taken to be in the Schrödinger picture, even though this equation seems at first look to emulate the Heisenberg equation of motion in the Heisenberg picture, with a crucial sign difference:
        i
        ℏ
              d
                A
                  (
                  H
                  )
              d
              t
        =
        −
        [
        H
        ,
          A
            (
            H
            )
        ]
        ,
    {\displaystyle i\hbar {\frac {dA^{(H)}}{dt}}=-[H,A^{(H)}]~,}
where 
          A
            (
            H
            )
        (
        t
        )
    {\displaystyle A^{(H)}(t)}
   is some Heisenberg picture operator; but in this picture the density matrix is not time-dependent, and the relative sign ensures that the time derivative of the expected value 
        ⟨
        A
        ⟩
    {\displaystyle \langle A\rangle }
   comes out the same as in the Schrödinger picture.
Taking the density operator to be in the Schrödinger picture makes sense, since it is composed of 'Schrödinger' kets and bras evolved in time, as per the Schrödinger picture. If the Hamiltonian is time-independent, this differential equation can be easily solved to yield
        ρ
        (
        t
        )
        =
          e
            −
            i
            H
            t
              /
            ℏ
        ρ
        (
        0
        )
          e
            i
            H
            t
              /
            ℏ
        .
    {\displaystyle \rho (t)=e^{-iHt/\hbar }\rho (0)e^{iHt/\hbar }.}
For a more general Hamiltonian, if 
        G
        (
        t
        )
    {\displaystyle G(t)}
   is the wavefunction propagator over some interval, then the time evolution of the density matrix over that same interval is given by
        ρ
        (
        t
        )
        =
        G
        (
        t
          )
            †
        ρ
        (
        0
        )
        G
        (
        t
        )
        .
    {\displaystyle \rho (t)=G(t)^{\dagger }\rho (0)G(t).}
The density matrix operator may also be realized in phase space. Under the Wigner map, the density matrix transforms into the equivalent Wigner function,
        W
        (
        x
        ,
        p
        )
                =
                  d
                  e
                  f
            1
              π
              ℏ
          ∫
            −
            ∞
            ∞
          ψ
            ∗
        (
        x
        +
        y
        )
        ψ
        (
        x
        −
        y
        )
          e
            2
            i
            p
            y
              /
            ℏ
        d
        y
        .
    {\displaystyle W(x,p){\stackrel {\mathrm {def} }{=}}{\frac {1}{\pi \hbar }}\int _{-\infty }^{\infty }\psi ^{*}(x+y)\psi (x-y)e^{2ipy/\hbar }\,dy~.}
The equation for the time-evolution of the Wigner function is then the Wigner-transform of the above von Neumann equation,
              ∂
              W
              (
              q
              ,
              p
              ,
              t
              )
              ∂
              t
        =
        −
        {
        {
        W
        (
        q
        ,
        p
        ,
        t
        )
        ,
        H
        (
        q
        ,
        p
        )
        }
        }
        ,
    {\displaystyle {\frac {\partial W(q,p,t)}{\partial t}}=-\{\{W(q,p,t),H(q,p)\}\}~,}
where H(q,p) is the Hamiltonian, and { { •,• } } is the Moyal bracket, the transform of the quantum commutator.
The evolution equation for the Wigner function is then analogous to that of its classical limit, the Liouville equation of classical physics. In the limit of vanishing Planck's constant ħ, W(q,p,t) reduces to the classical Liouville probability density function in phase space.
The classical Liouville equation can be solved using the method of characteristics for partial differential equations, the characteristic equations being Hamilton's equations. The Moyal equation in quantum mechanics similarly admits formal solutions in terms of quantum characteristics, predicated on the ∗−product of phase space, although, in actual practice, solution-seeking follows different methods.
The joint density matrix of a composite system of two systems A and B is described by 
          ρ
            A
            B
    {\displaystyle \rho _{AB}}
  . Then the subsystems are described by their reduced density operator.
          ρ
            A
        =
          tr
            B
        ⁡
          ρ
            A
            B
    {\displaystyle \rho _{A}=\operatorname {tr} _{B}\rho _{AB}}
          tr
            B
    {\displaystyle \operatorname {tr} _{B}}
   is called partial trace over system B. If A and B are two distinct and independent systems then 
          ρ
            A
            B
        =
          ρ
            A
        ⊗
          ρ
            B
    {\displaystyle \rho _{AB}=\rho _{A}\otimes \rho _{B}}
   which is a product state.
It is now generally accepted that the description of quantum mechanics in which all self-adjoint operators represent observables is untenable. For this reason, observables are identified with elements of an abstract C*-algebra A (that is one without a distinguished representation as an algebra of operators) and states are positive linear functionals on A. However, by using the GNS construction, we can recover Hilbert spaces which realize A as a subalgebra of operators.
Geometrically, a pure state on a C*-algebra A is a state which is an extreme point of the set of all states on A. By properties of the GNS construction these states correspond to irreducible representations of A.
The states of the C*-algebra of compact operators K(H) correspond exactly to the density operators, and therefore the pure states of K(H) are exactly the pure states in the sense of quantum mechanics.
The C*-algebraic formulation can be seen to include both classical and quantum systems. When the system is classical, the algebra of observables become an abelian C*-algebra. In that case the states become probability measures, as noted in the introduction.
