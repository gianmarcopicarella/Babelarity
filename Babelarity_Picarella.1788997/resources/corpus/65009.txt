The Karnaugh map, also known as the K-map, is a method to simplify boolean algebra expressions. Maurice Karnaugh introduced it in 1953 as a refinement of Edward Veitch's 1952 Veitch diagram. The Karnaugh map reduces the need for extensive calculations by taking advantage of humans' pattern-recognition capability. It also permits the rapid identification and elimination of potential race conditions.
The required boolean results are transferred from a truth table onto a two-dimensional grid where the cells are ordered in Gray code, and each cell position represents one combination of input conditions, while each cell value represents the corresponding output value. Optimal groups of 1s or 0s are identified, which represent the terms of a canonical form of the logic in the original truth table. These terms can be used to write a minimal boolean expression representing the required logic.
Karnaugh maps are used to simplify real-world logic requirements so that they can be implemented using a minimum number of physical logic gates. A sum-of-products expression can always be implemented using AND gates feeding into an OR gate, and a product-of-sums expression leads to OR gates feeding an AND gate. Karnaugh maps can also be used to simplify logic expressions in software design. Boolean conditions, as used for example in conditional statements, can get very complicated, which makes the code difficult to read and to maintain. Once minimised, canonical sum-of-products and product-of-sums expressions can be implemented directly using AND and OR logic operators.
Karnaugh maps are used to facilitate the simplification of Boolean algebra functions. For example, consider the Boolean function described by the following truth table.
Following are two different notations describing the same function in unsimplified Boolean algebra, using the Boolean variables 
        A
    {\displaystyle A}
  , 
        B
    {\displaystyle B}
  , 
        C
    {\displaystyle C}
  , 
        D
    {\displaystyle D}
  , and their inverses.
        f
        (
        A
        ,
        B
        ,
        C
        ,
        D
        )
        =
          ∑
          m
            i
        ,
        i
        ∈
        {
        6
        ,
        8
        ,
        9
        ,
        10
        ,
        11
        ,
        12
        ,
        13
        ,
        14
        }
    {\displaystyle f(A,B,C,D)=\sum _{}m_{i},i\in \{6,8,9,10,11,12,13,14\}}
   where 
          m
            i
    {\displaystyle m_{i}}
   are the minterms to map (i.e., rows that have output 1 in the truth table).
        f
        (
        A
        ,
        B
        ,
        C
        ,
        D
        )
        =
          ∏
          M
            i
        ,
        i
        ∈
        {
        0
        ,
        1
        ,
        2
        ,
        3
        ,
        4
        ,
        5
        ,
        7
        ,
        15
        }
    {\displaystyle f(A,B,C,D)=\prod _{}M_{i},i\in \{0,1,2,3,4,5,7,15\}}
   where 
          M
            i
    {\displaystyle M_{i}}
   are the maxterms to map (i.e., rows that have output 0 in the truth table).
In the example above, the four input variables can be combined in 16 different ways, so the truth table has 16 rows, and the Karnaugh map has 16 positions. The Karnaugh map is therefore arranged in a 4 × 4 grid.
The row and column indices (shown across the top, and down the left side of the Karnaugh map) are ordered in Gray code rather than binary numerical order. Gray code ensures that only one variable changes between each pair of adjacent cells. Each cell of the completed Karnaugh map contains a binary digit representing the function's output for that combination of inputs.
After the Karnaugh map has been constructed, it is used to find one of the simplest possible forms — a canonical form — for the information in the truth table. Adjacent 1s in the Karnaugh map represent opportunities to simplify the expression. The minterms ('minimal terms') for the final expression are found by encircling groups of 1s in the map. Minterm groups must be rectangular and must have an area that is a power of two (i.e., 1, 2, 4, 8…). Minterm rectangles should be as large as possible without containing any 0s. Groups may overlap in order to make each one larger. The optimal groupings in the example below are marked by the green, red and blue lines, and the red and green groups overlap. The red group is a 2 × 2 square, the green group is a 4 × 1 rectangle, and the overlap area is indicated in brown.
The cells are often denoted by a shorthand which describes the logical value of the inputs that the cell covers. For example, 
        A
        D
    {\displaystyle AD}
   would mean a cell which covers the 2x2 area where 
        A
    {\displaystyle A}
   and 
        D
    {\displaystyle D}
   are true, i.e. the cells numbered 13, 9, 15, 11 in the diagram above. On the other hand, 
        A
            D
            ¯
    {\displaystyle A{\overline {D}}}
   would mean the cells where 
        A
    {\displaystyle A}
   is true and 
        D
    {\displaystyle D}
   is false (that is, 
            D
            ¯
    {\displaystyle {\overline {D}}}
   is true).
The grid is toroidally connected, which means that rectangular groups can wrap across the edges (see picture). Cells on the extreme right are actually 'adjacent' to those on the far left; similarly, so are those at the very top and those at the bottom. Therefore, 
        A
            D
            ¯
    {\displaystyle A{\overline {D}}}
   can be a valid term—it includes cells 12 and 8 at the top, and wraps to the bottom to include cells 10 and 14—as is 
            B
            ¯
            D
            ¯
    {\displaystyle {\overline {B}}\,{\overline {D}}}
  , which includes the four corners.
Once the Karnaugh map has been constructed and the adjacent 1s linked by rectangular and square boxes, the algebraic minterms can be found by examining which variables stay the same within each box.
For the red grouping:
A is the same and is equal to 1 throughout the box, therefore it should be included in the algebraic representation of the red minterm.
B does not maintain the same state (it shifts from 1 to 0), and should therefore be excluded.
C does not change. It is always 0, so its complement, NOT-C, should be included. Thus, 
            C
            ¯
    {\displaystyle {\overline {C}}}
   should be included.
D changes, so it is excluded.
Thus the first minterm in the Boolean sum-of-products expression is 
        A
            C
            ¯
    {\displaystyle A{\overline {C}}}
  .
For the green grouping, A and B maintain the same state, while C and D change. B is 0 and has to be negated before it can be included. The second term is therefore 
        A
            B
            ¯
    {\displaystyle A{\overline {B}}}
  . Note it is fine that the green grouping overlaps with the red one.
In the same way, the blue grouping gives the term 
        B
        C
            D
            ¯
    {\displaystyle BC{\overline {D}}}
  .
The solutions of each grouping are combined: the normal form of the circuit is 
        A
            C
            ¯
        +
        A
            B
            ¯
        +
        B
        C
            D
            ¯
    {\displaystyle A{\overline {C}}+A{\overline {B}}+BC{\overline {D}}}
  .
Thus the Karnaugh map has guided a simplification of
                f
                (
                A
                ,
                B
                ,
                C
                ,
                D
                )
                =
                    A
                    ¯
                B
                C
                    D
                    ¯
                +
                A
                    B
                    ¯
                    C
                    ¯
                    D
                    ¯
                +
                A
                    B
                    ¯
                    C
                    ¯
                D
                +
                A
                    B
                    ¯
                C
                    D
                    ¯
                +
                A
                    B
                    ¯
                C
                D
                +
                A
                B
                    C
                    ¯
                    D
                    ¯
                +
                A
                B
                    C
                    ¯
                D
                +
                A
                B
                C
                    D
                    ¯
                =
                A
                    C
                    ¯
                +
                A
                    B
                    ¯
                +
                B
                C
                    D
                    ¯
    {\displaystyle {\begin{aligned}f(A,B,C,D)={}&{\overline {A}}BC{\overline {D}}+A{\overline {B}}\,{\overline {C}}\,{\overline {D}}+A{\overline {B}}\,{\overline {C}}D+A{\overline {B}}C{\overline {D}}+{}\\&A{\overline {B}}CD+AB{\overline {C}}\,{\overline {D}}+AB{\overline {C}}D+ABC{\overline {D}}\\={}&A{\overline {C}}+A{\overline {B}}+BC{\overline {D}}\end{aligned}}}
It would also have been possible to derive this simplification by carefully applying the axioms of boolean algebra, but the time it takes to do that grows exponentially with the number of terms.
The inverse of a function is solved in the same way by grouping the 0s instead.
The three terms to cover the inverse are all shown with grey boxes with different colored borders:
brown: 
            A
            ¯
            B
            ¯
    {\displaystyle {\overline {A}}\,{\overline {B}}}
gold: 
            A
            ¯
            C
            ¯
    {\displaystyle {\overline {A}}\,{\overline {C}}}
blue: 
        B
        C
        D
    {\displaystyle BCD}
This yields the inverse:
              f
              (
              A
              ,
              B
              ,
              C
              ,
              D
              )
            ¯
        =
            A
            ¯
            B
            ¯
        +
            A
            ¯
            C
            ¯
        +
        B
        C
        D
    {\displaystyle {\overline {f(A,B,C,D)}}={\overline {A}}\,{\overline {B}}+{\overline {A}}\,{\overline {C}}+BCD}
Through the use of De Morgan's laws, the product of sums can be determined:
                        f
                        (
                        A
                        ,
                        B
                        ,
                        C
                        ,
                        D
                        )
                      ¯
                    ¯
                =
                          A
                          ¯
                          B
                          ¯
                      +
                          A
                          ¯
                          C
                          ¯
                      +
                      B
                      C
                      D
                    ¯
                f
                (
                A
                ,
                B
                ,
                C
                ,
                D
                )
                =
                          A
                          ¯
                          B
                          ¯
                      +
                          A
                          ¯
                          C
                          ¯
                      +
                      B
                      C
                      D
                    ¯
                f
                (
                A
                ,
                B
                ,
                C
                ,
                D
                )
                =
                  (
                  A
                  +
                  B
                  )
                  (
                  A
                  +
                  C
                  )
                  (
                      B
                      ¯
                  +
                      C
                      ¯
                  +
                      D
                      ¯
                  )
    {\displaystyle {\begin{aligned}{\overline {\overline {f(A,B,C,D)}}}&={\overline {{\overline {A}}\,{\overline {B}}+{\overline {A}}\,{\overline {C}}+BCD}}\\f(A,B,C,D)&={\overline {{\overline {A}}\,{\overline {B}}+{\overline {A}}\,{\overline {C}}+BCD}}\\f(A,B,C,D)&=\left(A+B\right)\left(A+C\right)\left({\overline {B}}+{\overline {C}}+{\overline {D}}\right)\end{aligned}}}
Karnaugh maps also allow easy minimizations of functions whose truth tables include "don't care" conditions. A "don't care" condition is a combination of inputs for which the designer doesn't care what the output is. Therefore, "don't care" conditions can either be included in or excluded from any rectangular group, whichever makes it larger. They are usually indicated on the map with a dash or X.
The example on the right is the same as the example above but with the value of f(1,1,1,1) replaced by a "don't care". This allows the red term to expand all the way down and, thus, removes the green term completely.
This yields the new minimum equation:
        f
        (
        A
        ,
        B
        ,
        C
        ,
        D
        )
        =
        A
        +
        B
        C
            D
            ¯
    {\displaystyle f(A,B,C,D)=A+BC{\overline {D}}}
Note that the first term is just 
        A
    {\displaystyle A}
  , not 
        A
            C
            ¯
    {\displaystyle A{\overline {C}}}
  . In this case, the don't care has dropped a term (the green rectangle); simplified another (the red one); and removed the race hazard (removing the yellow term as shown in the following section on race hazards).
The inverse case is simplified as follows:
              f
              (
              A
              ,
              B
              ,
              C
              ,
              D
              )
            ¯
        =
            A
            ¯
            B
            ¯
        +
            A
            ¯
            C
            ¯
        +
            A
            ¯
        D
    {\displaystyle {\overline {f(A,B,C,D)}}={\overline {A}}\,{\overline {B}}+{\overline {A}}\,{\overline {C}}+{\overline {A}}D}
Karnaugh maps are useful for detecting and eliminating race conditions. Race hazards are very easy to spot using a Karnaugh map, because a race condition may exist when moving between any pair of adjacent, but disjoint, regions circumscribed on the map. However, because of the nature of Gray coding, adjacent has a special definition explained above - we're in fact moving on a torus, rather than a rectangle, wrapping around the top, bottom, and the sides.
In the example above, a potential race condition exists when C is 1 and D is 0, A is 1, and B changes from 1 to 0 (moving from the blue state to the green state). For this case, the output is defined to remain unchanged at 1, but because this transition is not covered by a specific term in the equation, a potential for a glitch (a momentary transition of the output to 0) exists.
There is a second potential glitch in the same example that is more difficult to spot: when D is 0 and A and B are both 1, with C changing from 1 to 0 (moving from the blue state to the red state). In this case the glitch wraps around from the top of the map to the bottom.
Whether glitches will actually occur depends on the physical nature of the implementation, and whether we need to worry about it depends on the application. In clocked logic, it is enough that the logic settles on the desired value in time to meet the timing deadline. In our example, we are not considering clocked logic.
In our case, an additional term of 
        A
            D
            ¯
    {\displaystyle A{\overline {D}}}
   would eliminate the potential race hazard, bridging between the green and blue output states or blue and red output states: this is shown as the yellow region (which wraps around from the bottom to the top of the right half) in the diagram to the right.
The term is redundant in terms of the static logic of the system, but such redundant, or consensus terms, are often needed to assure race-free dynamic performance.
Similarly, an additional term of 
            A
            ¯
        D
    {\displaystyle {\overline {A}}D}
   must be added to the inverse to eliminate another potential race hazard. Applying De Morgan's laws creates another product of sums expression for f, but with a new factor of 
          (
          A
          +
              D
              ¯
          )
    {\displaystyle \left(A+{\overline {D}}\right)}
  .
The following are all the possible 2-variable, 2 × 2 Karnaugh maps. Listed with each is the minterms as a function of 
        ∑
        m
        (
        )
    {\displaystyle \sum m()}
   and the race hazard free (see previous section) minimum equation. A minterm is defined as an expression that gives the most minimal form of expression of the mapped variables. All possible horizontal and vertical interconnected blocks can be formed. These blocks must be of the size of the powers of 2 (1, 2, 4, 8, 16, 32, ...). These expressions create a minimal logical mapping of the minimal logic variable expressions for the binary expressions to be mapped. Here are all the blocks with one field.
A block can be continued across the bottom, top, left, or right of the chart. That can even wrap beyond the edge of the chart for variable minimization. This is because each logic variable corresponds to each vertical column and horizontal row. A visualization of the k-map can be considered cylindrical. The fields at edges on the left and right are adjacent, and the top and bottom are adjacent. K-Maps for 4 variables must be depicted as a donut or torus shape. The four corners of the square drawn by the k-map are adjacent. Still more complex maps are needed for 5 variables and more.
Circuit minimization
Espresso heuristic logic minimizer
List of boolean algebra topics
Quine–McCluskey algorithm
Venn diagram
